{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatBot\n",
    "\n",
    "Jeffrey Leiva Cascante 2021016720\n",
    "\n",
    "Richard León Chinchilla 2019003759"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports necesarios y setup básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import os\n",
    "import string\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Lista de respuestas del chatbot\n",
    "answers = [\n",
    "    \"Our business hours are Monday to Friday from 9:00 AM to 6:00 PM.\",\n",
    "    \"You can make returns within the first 30 days of purchase.\",\n",
    "    \"We accept credit cards, PayPal, and bank transfers.\",\n",
    "    \"We ship nationwide. Delivery time varies depending on the location.\",\n",
    "    \"We offer a wide range of products available in our online store.\",\n",
    "    \"We offer warranties of up to 2 years on selected products.\",\n",
    "    \"For technical support, you can contact us through our web form.\",\n",
    "    \"You can place an order by following the steps on our shopping page.\",\n",
    "    \"For any questions, you can contact us through our chat or email.\",\n",
    "    \"To check the status of your order, go to the 'My Orders' section.\"\n",
    "]\n",
    "\n",
    "file_name = 'answers_embeddings.json'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de funciones para el funcionamiento del chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.lemma_ for token in doc if token.text not in STOP_WORDS and token.text not in string.punctuation]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Función para obtener el embedding de un texto utilizando\n",
    "def get_embedding(text):\n",
    "    return nlp(text).vector\n",
    "\n",
    "# Función para guardar los embeddings en JSON\n",
    "def save_embeddings_json(embeddings, name_file):\n",
    "    with open(name_file, 'w') as f:\n",
    "        json.dump(embeddings, f)\n",
    "\n",
    "# Función para cargar embeddings desde un archivo JSON\n",
    "def load_embeddings_json(name_file):\n",
    "    with open(name_file, 'r') as f:\n",
    "        embeddings_list = json.load(f)\n",
    "    return [np.array(embedding) for embedding in embeddings_list]\n",
    "\n",
    "# Función para calcular la similitud de coseno entre la pregunta y las respuestas\n",
    "def calculate_similarity(embedding_question, embeddings_answers):\n",
    "    # Calcula la similitud de coseno entre la pregunta y cada respuesta\n",
    "    similarities = cosine_similarity([embedding_question], embeddings_answers)\n",
    "    return similarities[0]\n",
    "\n",
    "# Función para seleccionar la mejor respuesta en función de la similitud\n",
    "def pick_best_answer(similarities):\n",
    "    index_best_answer = np.argmax(similarities)  # Índice de la respuesta más similar\n",
    "    return index_best_answer, max(similarities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisar si ya existen los embeddings de las respuestas\n",
    "\n",
    "Si no existen en un archivo .json entonces los crea y almacena, si ya existen, simplemente los carga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo de embeddings ya existe. Cargando embeddings...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embeddings_respuestas = []\n",
    "if os.path.exists(file_name):\n",
    "    print(\"El archivo de embeddings ya existe. Cargando embeddings...\")\n",
    "    embeddings_respuestas = load_embeddings_json(file_name)\n",
    "else:\n",
    "    print(\"El archivo de embeddings no existe. Generando embeddings...\")\n",
    "    # Generar los embeddings de las respuestas\n",
    "    preprocessed_answers = [preprocess_text(answer) for answer in answers]\n",
    "    embeddings_respuestas = [get_embedding(answer) for answer in preprocessed_answers]\n",
    "    \n",
    "    # Guardar los embeddings en el archivo JSON\n",
    "    embeddings_respuestas_list = [embedding.tolist() for embedding in embeddings_respuestas]\n",
    "    save_embeddings_json(embeddings_respuestas_list, file_name)\n",
    "    print(f\"Embeddings generados y guardados en {file_name}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testear con una pregunta y ver la respuesta que tiene una mayor similitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor respuesta: For technical support, you can contact us through our web form.\n",
      "Similitud: 0.695706236471523\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Obtener la respuesta del usuario y hacerle el preprocesamiento\n",
    "question = input(\"Haz tu pregunta: \")\n",
    "preprocessed_question = preprocess_text(question)\n",
    "\n",
    "# Obtener el emebedding de la pregunta\n",
    "embedding_question = get_embedding(preprocessed_question)\n",
    "\n",
    "# Calcular la similitud entre pregunta y respuestas\n",
    "similarities = calculate_similarity(embedding_question, embeddings_respuestas)\n",
    "\n",
    "# Seleccionar la mejor respuesta basandose en la similitud\n",
    "index_best_answer, maximum_similarity = pick_best_answer(similarities)\n",
    "\n",
    "# Mostrar la respuesta más similar al usuario\n",
    "print(f\"Mejor respuesta: {answers[index_best_answer]}\")\n",
    "print(f\"Similitud: {maximum_similarity}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
